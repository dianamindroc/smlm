dataset:
  root_folder: '/home/dim26fa/data/sim_cube_tetra'
  classes: ['all']
  suffix: '.csv'
  highest_shape: 500
  remove_part_prob: 0.6
  dataset_type: 'tetra'
  remove_corners: False
  number_corners_remove: [0,1,2]
  remove_outliers: False
  anisotropy: False
  anisotropy_factor: 0.6
  anisotropy_axis: 'z'
  initial_alpha: 1.0
  number_classes: 2
model: 'pcn'
train:
  lr: 0.0001
  min_lr: 0.00001
  channels: 3
  batch_size: 16
  num_workers: 0
  momentum: 0.9
  momentum2: 0.999
  num_epochs: 500
  loss: 'cd'
  gml_sigma: 2
  early_stop_patience: 50
  log_dir: '/home/dim26fa/coding/training'
  scheduler_type: reduce
  scheduler_factor: 0.75
  scheduler_patience: 20
  gamma: 0.0001 # for other than stepLR use smaller values e.g. 0.0001
  step_size: 50
  ignore_zeros: False
  augmentation: True
  initial_alpha:
  loss1_improvement_threshold: 30
  min_improvement_epochs: 10
  classifier: True
  pretrained: False
  #ckpt: '/home/dim26fa/coding/training/logs_pcn_20241009_225619/best_l1_cd.pth'
  ckpt: None
  autoencoder: False
  lambda_reg: 0.01
  alpha_density: 0.5
  beta_sparsity: 0.02
  num_dense: 1470
  latent_dim: 1024
  grid_size: 2
  use_wandb: False
  export_samples_every: 0
  log_pointclouds: False
pcn_config:
  coarse_dim: 16384
  fine_dim: 1024
adapointr_config:
  NAME: 'AdaPoinTr'
  num_query: 512
  num_points: 16384
  center_num: [512, 256]
  global_feature_dim: 1024
  encoder_type: 'graph'
  decoder_type: 'fc'
  encoder_config:
    embed_dim: 384
    depth: 6
    num_heads: 6
    k: 8
    n_group: 2
    mlp_ratio: 2.0
    block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn']
    combine_style: 'concat'
  decoder_config:
    embed_dim: 384
    depth: 8
    num_heads: 6
    k: 8
    n_group: 2
    mlp_ratio: 2.0
    self_attn_block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn']
    self_attn_combine_style: 'concat'
    cross_attn_block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn']
    cross_attn_combine_style: 'concat'
