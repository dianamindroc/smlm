{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1fbb60",
   "metadata": {},
   "source": [
    "# Network Training Tutorial\n",
    "\n",
    "This notebook walks through training the PCN point-cloud completion network on a small synthetic dataset generated with the DNA origami simulator. The goal is to demonstrate the end-to-end workflow: environment setup, data preparation, model training, and qualitative evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8485404",
   "metadata": {},
   "source": [
    "## 1. Environment setup\n",
    "\n",
    "Run the following cell if you are executing this notebook in a fresh environment (for example, Google Colab). It checks whether the repository is available locally, clones it when needed, and installs the required Python dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "START_DIR = pathlib.Path.cwd()\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not (START_DIR / 'smlm').exists():\n",
    "        !git clone https://github.com/dianamindroc/smlm.git\n",
    "    START_DIR = START_DIR / 'smlm'\n",
    "\n",
    "for candidate in [START_DIR, *START_DIR.parents]:\n",
    "    if (candidate / 'setup.py').exists():\n",
    "        PROJECT_ROOT = candidate\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError('Could not locate the repository root. Please ensure you run this notebook from within the smlm project.')\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f'Working directory set to: {PROJECT_ROOT}')\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf9917",
   "metadata": {},
   "source": [
    "## 2. Imports and helper functions\n",
    "\n",
    "We load the simulator dataset, data transforms, the PCN model, and Chamfer distance loss. A helper plotting function is included for later visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009de25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset.SMLMSimulator import DNAOrigamiSimulator\n",
    "from model_architectures import pcn, losses\n",
    "from model_architectures.transforms import Padding, ToTensor\n",
    "from helpers.misc import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "def plot_point_cloud_triplet(gt, partial, reconstructed, title_suffix=''):\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    entries = [\n",
    "        (gt, 'Ground truth'),\n",
    "        (partial, 'Input (partial)'),\n",
    "        (reconstructed, 'Reconstruction')\n",
    "    ]\n",
    "    for idx, (cloud, title) in enumerate(entries):\n",
    "        ax = fig.add_subplot(1, 3, idx + 1, projection='3d')\n",
    "        ax.scatter(cloud[:, 0], cloud[:, 1], cloud[:, 2], s=4)\n",
    "        ax.set_title(f\"{title} {title_suffix}\")\n",
    "        ax.set_axis_off()\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0318ab5",
   "metadata": {},
   "source": [
    "## 3. Build synthetic training and validation datasets\n",
    "\n",
    "We use the DNA Origami simulator to generate paired complete and partial point clouds. Padding guarantees a fixed number of points per sample so the model can process mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dye properties for the simulator\n",
    "dye_properties = {\n",
    "    'density_range': (10, 40),\n",
    "    'blinking_times_range': (10, 30),\n",
    "    'intensity_range': (500, 2500),\n",
    "    'precision_range': (0.5, 2.0)\n",
    "}\n",
    "\n",
    "# Number of points after padding (kept modest for a fast tutorial run)\n",
    "MAX_POINTS = 384\n",
    "transform_pipeline = transforms.Compose([Padding(MAX_POINTS), ToTensor()])\n",
    "\n",
    "full_dataset = DNAOrigamiSimulator(\n",
    "    num_samples=240,\n",
    "    structure_type='box',\n",
    "    dye_properties=dye_properties,\n",
    "    augment=True,\n",
    "    remove_corners=True,\n",
    "    transform=transform_pipeline\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}, validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba3980",
   "metadata": {},
   "source": [
    "## 4. Initialise the PCN model and optimizer\n",
    "\n",
    "We keep the architecture compact (reduced latent size and density) to ensure the tutorial runs quickly on CPU or a small GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "NUM_DENSE = MAX_POINTS\n",
    "LATENT_DIM = 512\n",
    "GRID_SIZE = 2\n",
    "\n",
    "model = pcn.PCN(num_dense=NUM_DENSE, latent_dim=LATENT_DIM, grid_size=GRID_SIZE, classifier=False, channels=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameters: {param_count / 1_000_000:.2f} M')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f4bb0",
   "metadata": {},
   "source": [
    "## 5. Training and validation loops\n",
    "\n",
    "Chamfer distance is minimised on both coarse and fine outputs. We track the average loss per epoch for monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b123bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "def chamfer_l1(pred, target):\n",
    "    try:\n",
    "        return losses.cd_loss_l1(pred, target)\n",
    "    except RuntimeError as exc:\n",
    "        if 'chamfer' not in str(exc).lower():\n",
    "            raise\n",
    "        # Fallback implementation using torch.cdist for CPU-only environments\n",
    "        dist = torch.cdist(pred, target)  # [B, N, M]\n",
    "        min_pred = dist.min(dim=-1)[0]\n",
    "        min_target = dist.min(dim=-2)[0]\n",
    "        return (min_pred.mean() + min_target.mean()) / 2\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    running_loss = 0.0\n",
    "    num_samples = 0\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for batch in loader:\n",
    "        target_full = batch['pc'].to(device)\n",
    "        partial_input = batch['partial_pc'].to(device)\n",
    "\n",
    "        partial_input = partial_input.permute(0, 2, 1)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            coarse, fine, _, _ = model(partial_input)\n",
    "            loss_fine = chamfer_l1(fine, target_full)\n",
    "            loss_coarse = chamfer_l1(coarse, target_full)\n",
    "            loss = loss_fine + alpha * loss_coarse\n",
    "\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "        batch_size = partial_input.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        num_samples += batch_size\n",
    "\n",
    "    return running_loss / max(1, num_samples)\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "train_history, val_history = [], []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = run_epoch(train_loader, train=True)\n",
    "    val_loss = run_epoch(val_loader, train=False)\n",
    "    train_history.append(train_loss)\n",
    "    val_history.append(val_loss)\n",
    "    print(f\"Epoch {epoch:02d} | train loss: {train_loss:.4f} | val loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1053fdc0",
   "metadata": {},
   "source": [
    "## 6. Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_history, label='train')\n",
    "plt.plot(val_history, label='validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Chamfer loss')\n",
    "plt.title('Training progress')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30460c23",
   "metadata": {},
   "source": [
    "## 7. Qualitative inspection\n",
    "\n",
    "We visualise a validation sample, comparing the ground truth, the partial input, and the reconstructed point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b60d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example_batch = next(iter(val_loader))\n",
    "partial_example = example_batch['partial_pc'].to(device)\n",
    "full_example = example_batch['pc'].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, fine_pred, _, _ = model(partial_example.permute(0, 2, 1))\n",
    "\n",
    "reconstructed = fine_pred[0].cpu().numpy()\n",
    "partial_np = partial_example[0].cpu().numpy()\n",
    "full_np = full_example[0].cpu().numpy()\n",
    "\n",
    "plot_point_cloud_triplet(full_np, partial_np, reconstructed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f70ada",
   "metadata": {},
   "source": [
    "## 8. Save the trained weights (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22601d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = pathlib.Path('artifacts')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "model_path = OUTPUT_DIR / 'pcn_demo_weights.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print('Model checkpoint saved to', model_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9acc9",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Replace the simulator with experimental datasets by pointing the configuration to your data directories.\n",
    "- Integrate logging (e.g. Weights & Biases) for richer monitoring.\n",
    "- Extend the model with classification heads or alternative loss functions, as done in the full training scripts under `scripts/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
